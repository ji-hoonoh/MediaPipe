#!/usr/bin/env python
# -*- coding: utf-8 -*-

import cv2
import mediapipe as mp

# =========================================
# ğŸ§© Mediapipe ì´ˆê¸°í™” (Face Detectionìœ¼ë¡œ ë³€ê²½)
# =========================================
# mp.solutions.hands ëŒ€ì‹  mp.solutions.face_detection ì‚¬ìš©
mp_face_detection = mp.solutions.face_detection
mp_drawing = mp.solutions.drawing_utils

# FaceDetection ëª¨ë¸ ì´ˆê¸°í™”
face_detection = mp_face_detection.FaceDetection(
    model_selection=1, # 0ì€ ì§§ì€ ë²”ìœ„ (ê°€ê¹Œìš´ ì–¼êµ´), 1ì€ ì „ì²´ ë²”ìœ„ (ë¨¼ ì–¼êµ´ í¬í•¨)
    min_detection_confidence=0.5  # íƒì§€ ì‹ ë¢°ë„
)

# =========================================
# ğŸ“¸ ì¹´ë©”ë¼ ì—°ê²°
# =========================================
# cap = cv2.VideoCapture(0)             # ê¸°ë³¸ ì¹´ë©”ë¼ ì‚¬ìš©ì‹œ
cap = cv2.VideoCapture("face.mp4")    # ë™ì˜ìƒ íŒŒì¼ ì‚¬ìš© ì‹œ (íŒŒì¼ ì´ë¦„ ë³€ê²½ ê¶Œì¥)

print("ğŸ“· ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ì‹œì‘ â€” ESCë¥¼ ëˆŒëŸ¬ ì¢…ë£Œí•©ë‹ˆë‹¤.")

while cap.isOpened():
    success, image = cap.read()
    if not success:
        print("âš ï¸ í”„ë ˆì„ì„ ì½ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ ì—°ê²°ì„ í™•ì¸í•˜ê±°ë‚˜ ë™ì˜ìƒ íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        break

    # ì¢Œìš° ë°˜ì „ (ì…€ì¹´ ë·°)
    image = cv2.flip(image, 1)

    # BGR â†’ RGB ë³€í™˜
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # ì–¼êµ´ ê²€ì¶œ ìˆ˜í–‰ (hands.process ëŒ€ì‹  face_detection.process ì‚¬ìš©)
    result = face_detection.process(image_rgb)

    # ğŸ§‘â€ ì–¼êµ´ ì˜ì—­ í‘œì‹œ
    if result.detections:
        # result.multi_hand_landmarks ëŒ€ì‹  result.detections ì‚¬ìš©
        for detection in result.detections:
            # ì–¼êµ´ ì˜ì—­(Bounding box) ë° 6ê°œì˜ íŠ¹ì§•ì (ëœë“œë§ˆí¬) ê·¸ë¦¬ê¸°
            mp_drawing.draw_detection(
                image, 
                detection,
                # Face Detectionì€ ìŠ¤íƒ€ì¼ì„ ë³„ë„ë¡œ ì œê³µí•˜ì§€ ì•Šê³  ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
            )
            
            # (ì„ íƒ ì‚¬í•­: ì–¼êµ´ ê°ì§€ ì˜ì—­ ìœ„ì— í…ìŠ¤íŠ¸ ì¶”ê°€ ê°€ëŠ¥)
            # image_height, image_width, _ = image.shape
            # bbox_c = detection.location_data.relative_bounding_box
            # x_min = int(bbox_c.xmin * image_width)
            # y_min = int(bbox_c.ymin * image_height)
            # cv2.putText(image, f'{detection.score[0]*100:.2f}%', (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)


    # í™”ë©´ í‘œì‹œ
    cv2.imshow('ğŸ§‘â€ MediaPipe Face Detector', image)

    # ESC í‚¤ë¡œ ì¢…ë£Œ
    if cv2.waitKey(5) & 0xFF == 27:
        print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        break

# =========================================
# ğŸ”š ì¢…ë£Œ ì²˜ë¦¬
# =========================================
cap.release()
cv2.destroyAllWindows()
face_detection.close() # ëª¨ë¸ ê°ì²´ í•´ì œ
